{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as spio\n",
    "from scipy.io import savemat\n",
    "from pathlib import Path\n",
    "import json\n",
    "from utils import loadmat_dicts\n",
    "\n",
    "from Toolbox_GCSR.Preprocessing import Processor\n",
    "from Toolbox_GCSR.utility import eval_band, eval_band_cv\n",
    "from Toolbox_GCSR.EGCSR_BS_Ranking import EGCSR_BS_Ranking\n",
    "\n",
    "from Toolbox_bombs.runner import main\n",
    "from Toolbox_bombs.utils import Arguments\n",
    "\n",
    "#To use matlab engine. see: https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html\n",
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "\n",
    "eng.addpath(eng.genpath(\"Toolbox_SVD\"));\n",
    "eng.addpath(eng.genpath(\"Toolbox_OCF\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Importation and adequation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectral dataset must be in .mat files, for signatires matrix should be (samples, wavelengths)\n",
    "#Load from .mat\n",
    "\n",
    "#root for datasets\n",
    "pwdpath=os.getcwd()\n",
    "root = f\"{pwdpath}\\HSI_Files\\\\\"\n",
    "\n",
    "datasetName = \"Corn20220623\"\n",
    "\n",
    "im_, gt_ = f'{datasetName}Data', f'{datasetName}Labels'\n",
    "#results dir\n",
    "result = f'{pwdpath}\\Masters_Results\\{datasetName}\\\\'\n",
    "\n",
    "\n",
    "hsi_path = {'img_path': f'{root}{im_}.mat', 'gt_path': f'{root}{gt_}.mat'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Band selection is preformed for each iter*factor number of bands. Example: iter = 2 and factor 16, best 16 and 32 best discriminant bands will be selected. \n",
    "\n",
    "#The number of iterations and number of selected bands\n",
    "iter = 8\n",
    "factor = 4\n",
    "\n",
    "#Two experiments were presented, most plant stress datasets have 4 clases of 25% differences in nutrition. Experiment 1 takes all, Experiment 2 takes 50% and 100% nutrition. \n",
    "#Flag for reduced dataset. 0 full dataset, 1 only classes 1 and 4.\n",
    "reduced = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(data_m, band_num):\n",
    "\n",
    "    #data_m = eng.double(eng.importdata(hsi_path['img_path']))\n",
    "\n",
    "    select_svd = eng.svd_function(data_m, band_num);\n",
    "\n",
    "    bands = np.array(select_svd)\n",
    "\n",
    "    bands = bands.reshape(1,band_num)\n",
    "\n",
    "    bands = bands[0]\n",
    "\n",
    "    bands = bands - 1\n",
    "    \n",
    "    return bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCF Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ocf(data_m, band_num):\n",
    "\n",
    "    #data_m = eng.double(eng.importdata(hsi_path['img_path']))\n",
    "\n",
    "    select_ocf = eng.ocf_trc_fdpc(data_m, band_num);\n",
    "\n",
    "    bands = np.array(select_ocf)\n",
    "\n",
    "    bands = bands.reshape(1,band_num)\n",
    "\n",
    "    bands = bands[0]\n",
    "\n",
    "    bands = bands - 1\n",
    "\n",
    "    return bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOMBS Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(\n",
    "    os.getenv(\"Bombs_results\", os.path.join(\"..\", \"..\", \"results\")),\n",
    "    \"bombs_band_selection\"\n",
    ")\n",
    "\n",
    "def bombs(hsi_path, bands_num):\n",
    "\n",
    "    arguments = Arguments(\n",
    "            bands_per_antibody=bands_num,\n",
    "            data_path = hsi_path['img_path'],\n",
    "            ref_map_path = hsi_path['gt_path'],\n",
    "            dest_path=RESULTS_DIR,\n",
    "            Gmax=6,\n",
    "            Na=10,\n",
    "            Nd=25,\n",
    "            Nc=25,\n",
    "            TD_size=30,\n",
    "            P_init_size=100,\n",
    "        )\n",
    "    return main(args=arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCSR Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def EGCSR(hsi_path, bands_num):\n",
    "\n",
    "    p = Processor()\n",
    "    hsi_data, _ = p.prepare_data(hsi_path['img_path'], hsi_path['gt_path'])\n",
    "\n",
    "    alg_Ranking = EGCSR_BS_Ranking(bands_num, regu_coef=1e2, n_neighbors=3, ro=0.8)\n",
    "    alg_Ranking.predict(hsi_data)\n",
    "    return alg_Ranking.band_indx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms to be used in selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of band selection methods\n",
    "BS_functions = []\n",
    "#EGCSR not used due to poor results in later classification\n",
    "#BS_functions.append(EGCSR)\n",
    "BS_functions.append(bombs)\n",
    "BS_functions.append(svd)\n",
    "BS_functions.append(ocf)\n",
    "\n",
    "#dictionary for subsets selected from all algorithms\n",
    "bands_selected = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### band selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matlab is currently creating a memory leak each time data is passed. Created here 1 time to avoid this.  \n",
    "data_m = eng.double(eng.importdata(hsi_path['img_path']))\n",
    "\n",
    "#iterates band selection algorithms\n",
    "for alg in BS_functions:\n",
    "\n",
    "    #Dictionary entry for bands selection. one numpy array will save al results for this method. \n",
    "    bands_selected[alg.__name__] = np.zeros((iter,factor*iter)).astype(int)\n",
    "\n",
    "    print(alg.__name__ + ' START')\n",
    "    for i in range(iter):\n",
    "        \n",
    "        band_count = (i+1)*factor\n",
    "\n",
    "        print(f\"Selecting {band_count} bands...\")\n",
    "\n",
    "        #If algorithm is imported from matlab... use data_m\n",
    "        if alg.__name__ == \"svd\" or alg.__name__ == \"ocf\":\n",
    "            \n",
    "            alg_bands = alg(data_m, band_count)\n",
    "\n",
    "        #To select bands for other algothms, gives data directory\n",
    "        else:\n",
    "\n",
    "            alg_bands = alg(hsi_path, band_count)\n",
    "\n",
    "        print(f\"Best {band_count} bands for {datasetName} are: {alg_bands}\")\n",
    "\n",
    "        #saves selected bands in numpy array\n",
    "        bands_selected[alg.__name__][i,:len(alg_bands)] = alg_bands.astype(int)\n",
    "\n",
    "    print(alg.__name__ + ' ENDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WILL DELETE PREVIOUS RESULTS. CAUTION IS ADVISED\n",
    "\n",
    "#only use if experiment changes. else, load selected bands.\n",
    "#saves selected bands \n",
    "savemat(result + datasetName + \"Bands.mat\", bands_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bombs (8, 32)\n",
      "svd (8, 32)\n",
      "ocf (8, 32)\n"
     ]
    }
   ],
   "source": [
    "#Load saved selected bands\n",
    "saved_bands = spio.loadmat(result + datasetName + \"Bands.mat\")\n",
    "bands_selected = {}\n",
    "for key in saved_bands.keys():\n",
    "    if \"__\" not in key:\n",
    "        bands_selected[key] = np.array(saved_bands[key])\n",
    "        print(key, bands_selected[key].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification and visualizarion imports\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification algorithms definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification algorithms to use\n",
    "\n",
    "#parameters found by grid search\n",
    "\n",
    "#Creates RandomForest Clasiffier\n",
    "RF = RandomForestClassifier(max_depth = 60, min_samples_leaf = 3, min_samples_split = 6, n_estimators = 400,random_state=0)\n",
    "\n",
    "#Creates Svm Clasiffier\n",
    "SVM = SVC(C = 2000, kernel = 'poly', degree = 5, gamma = 1, random_state=0)\n",
    "\n",
    "#Creates Multi-Leyer perceptron classifier\n",
    "MLP = MLPClassifier(hidden_layer_sizes=(500,300,100,50), activation='relu', alpha= 0.000001, solver='adam', random_state=0)\n",
    "\n",
    "#dictionary to save classifier algorithms objects, must have .fit and a .predict methods\n",
    "Classifiers = {}\n",
    "Classifiers[\"RF\"] = RF\n",
    "Classifiers[\"SVM\"] = SVM\n",
    "Classifiers[\"MLP\"] = MLP\n",
    "\n",
    "#creates dictionaries to save results for every selected bandset\n",
    "Accuracy_values = {}\n",
    "\n",
    "for c in Classifiers:\n",
    "    Accuracy_values[c] = {}\n",
    "\n",
    "    for alg in bands_selected:\n",
    "        Accuracy_values[c][alg] = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data, labels and wavelength loading\n",
    "\n",
    "Wavelength =  pd.read_csv(root + datasetName + \"wavelength.txt\", sep = '\\s+', header= None)\n",
    "\n",
    "Labels = spio.loadmat(hsi_path['gt_path'])\n",
    "for key in Labels.keys():\n",
    "    if \"__\" not in key:\n",
    "        Labels = Labels[key]\n",
    "        break\n",
    "Labels = np.array(Labels)\n",
    "\n",
    "if Labels.shape[0] < Labels.shape[1]:\n",
    "    Labels = Labels.T\n",
    "\n",
    "Data = spio.loadmat(hsi_path['img_path'])\n",
    "for key in Data.keys():\n",
    "    if \"__\" not in key:\n",
    "        Data = Data[key]\n",
    "        break\n",
    "Data = np.array(Data)\n",
    "\n",
    "if Data.shape[0] != Labels.shape[0]:\n",
    "    Data = Data.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section takes clases 50% and 100% of nutrition of experiment 2 flag is 1\n",
    "if reduced == 1:\n",
    "    datasetName += \"redu50\"\n",
    "    Data_filtered = []\n",
    "    Labels_filtered = []\n",
    "\n",
    "    for i in range(Data.shape[0]):\n",
    "        \n",
    "        if key == \"EGCSR\":\n",
    "            continue\n",
    "\n",
    "        #ignoring middle classes to classifie with two\n",
    "        if reduced == 1:\n",
    "\n",
    "            if Labels[i] == 2 or Labels[i] == 4:\n",
    "                \n",
    "                Data_filtered.append(Data[i,:])\n",
    "                Labels_filtered.append(Labels[i])\n",
    "\n",
    "        else: \n",
    "\n",
    "            Data_filtered.append(Data[i,:])\n",
    "            Labels_filtered.append(Labels[i])\n",
    "\n",
    "    Data = np.array(Data_filtered)\n",
    "    Labels = np.array(Labels_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1)\n",
      "(2033, 1485)\n",
      "(2033, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Wavelength.shape)\n",
    "print(Data.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification over all selected band sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2033, 4)\n",
      "Processing:  bombs 4\n",
      "0.46885245901639344 RF\n",
      "0.4918032786885246 SVM\n",
      "0.4885245901639344 MLP\n",
      "(2033, 8)\n",
      "Processing:  bombs 8\n",
      "0.4918032786885246 RF\n",
      "0.5540983606557377 SVM\n",
      "0.4163934426229508 MLP\n",
      "(2033, 12)\n",
      "Processing:  bombs 12\n",
      "0.5344262295081967 RF\n",
      "0.5967213114754099 SVM\n",
      "0.46557377049180326 MLP\n",
      "(2033, 16)\n",
      "Processing:  bombs 16\n",
      "0.5606557377049181 RF\n",
      "0.6786885245901639 SVM\n",
      "0.5049180327868853 MLP\n",
      "(2033, 20)\n",
      "Processing:  bombs 20\n",
      "0.580327868852459 RF\n",
      "0.6721311475409836 SVM\n",
      "0.5540983606557377 MLP\n",
      "(2033, 24)\n",
      "Processing:  bombs 24\n",
      "0.5442622950819672 RF\n",
      "0.6918032786885245 SVM\n",
      "0.4163934426229508 MLP\n",
      "(2033, 28)\n",
      "Processing:  bombs 28\n",
      "0.5901639344262295 RF\n"
     ]
    }
   ],
   "source": [
    "#Iterates over bands sets \n",
    "for alg in bands_selected:      \n",
    "\n",
    "    #iterate \n",
    "    for i in range(iter):\n",
    "\n",
    "        #number of bands in current iteration\n",
    "        b_count = (i+1)*factor\n",
    "\n",
    "        #takes selected bands from dataset\n",
    "        DataSelected = Data[:,bands_selected[alg][i,0:b_count]]\n",
    "\n",
    "        print(DataSelected.shape)\n",
    "\n",
    "        #Prints bands to process\n",
    "        print(\"Processing: \", alg, b_count)\n",
    "\n",
    "        # Split dataset into training set and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(DataSelected, Labels,\n",
    "                                                            test_size=0.15, random_state=11, stratify = Labels)\n",
    "\n",
    "        for C in Classifiers:\n",
    "        \n",
    "            Classifiers[C].fit(X_train, y_train.ravel())\n",
    "\n",
    "            #Prediction of test set using trained model\n",
    "            test_prediction = Classifiers[C].predict(X_test)\n",
    "\n",
    "            accuracy = metrics.accuracy_score(y_test,test_prediction)\n",
    "\n",
    "            print(accuracy, C)\n",
    "            Accuracy_values[C][alg].append(accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WILL DELETE PREVIOUS RESULTS. CAUTION IS ADVISED\n",
    "\n",
    "#only use if experiment changes. else, load accuracy.\n",
    "\n",
    "#save accuracy values\n",
    "savemat(result + datasetName + \"Accuracy.mat\", Accuracy_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load accuracy values\n",
    "Accuracy = loadmat_dicts(result + datasetName + \"Accuracy.mat\")\n",
    "Accuracy_values = {}\n",
    "for key in Accuracy.keys():\n",
    "    if \"__\" not in key:\n",
    "        Accuracy_values[key] = np.array(Accuracy[key])\n",
    "        print(key, Accuracy_values[key].shape)\n",
    "print(Accuracy_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets each selection methon accuracy resutls to dictionaries\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "Dataframes_dict = {}\n",
    "\n",
    "Dataframes_dict[\"Random Forest\"] = pd.DataFrame( Accuracy_values['RF'].item())\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(Dataframes_dict['Random Forest'])\n",
    "\n",
    "Dataframes_dict[\"Support Vector Machine\"] = pd.DataFrame( Accuracy_values['SVM'].item())\n",
    "\n",
    "print(\"Support Vector Machine\")\n",
    "print(Dataframes_dict['Support Vector Machine'])\n",
    "\n",
    "Dataframes_dict[\"Multi Layer Perceptron\"] = pd.DataFrame( Accuracy_values['MLP'].item())\n",
    "\n",
    "print(\"Multi Layer Perceptron\")\n",
    "print(Dataframes_dict['Multi Layer Perceptron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates latex tables of accuracies\n",
    "row = []\n",
    "for i in range(iter):\n",
    "    row.append(str((i+1)*factor))\n",
    "for key, value in Dataframes_dict.items():\n",
    "    value.index = row\n",
    "    print(\"With classifier \", key , \"classification results are: \\n\", value.round(3).to_latex(bold_rows=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds maximum accuracy classification values\n",
    "row = []\n",
    "MaxValues = {}\n",
    "MaxAccuracy = {}\n",
    "MaxAccuracy[\"acc\"] = 0\n",
    "for i in range(iter):\n",
    "    row.append(str((i+1)*factor))\n",
    "    \n",
    "for key, value in Dataframes_dict.items():\n",
    "    value.index = row\n",
    "    print(\"For Classifier \"+ key)\n",
    "    \n",
    "    MaxValues[key] = {\"algorithm\" : value.columns.tolist(),\"Max accuracy\": value.max().tolist(),\"Max bands\": value.idxmax(axis=0).tolist()}\n",
    "\n",
    "    m = max(MaxValues[key][\"Max accuracy\"])\n",
    "\n",
    "    if m > MaxAccuracy[\"acc\"]:\n",
    "        MaxAccuracy[\"acc\"] = m\n",
    "        MaxIndex = MaxValues[key][\"Max accuracy\"].index(m)\n",
    "        MaxAccuracy[\"algorithm\"] = MaxValues[key][\"algorithm\"][MaxIndex]\n",
    "        MaxAccuracy[\"band num\"] = int(MaxValues[key][\"Max bands\"][MaxIndex])\n",
    "        \n",
    "#adds bands to max accuracy\n",
    "MaxAccuracy[\"bands\"] = np.sort(bands_selected[MaxAccuracy[\"algorithm\"]][int((MaxAccuracy[\"band num\"] / factor) - 1), 0:MaxAccuracy[\"band num\"]])\n",
    "\n",
    "print(MaxAccuracy)\n",
    "\n",
    "#saves best selected bands\n",
    "savemat(result + datasetName + \"MaxAccuracy.mat\", MaxAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load maximum accuracy results\n",
    "savedMax = loadmat_dicts(result + datasetName + \"MaxAccuracy.mat\")\n",
    "MaxAccuracy = {}\n",
    "for key in savedMax.keys():\n",
    "    if \"__\" not in key:\n",
    "        MaxAccuracy[key] = np.array(savedMax[key])\n",
    "        print(key, MaxAccuracy[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates latex table for maximum accuracy bands\n",
    "\n",
    "bandsDataframe = pd.DataFrame({'Band Number': MaxAccuracy[\"bands\"], 'Wavelength': np.reshape(Wavelength.iloc[MaxAccuracy[\"bands\"]].values, len(MaxAccuracy[\"bands\"])) })\n",
    "\n",
    "#Generate latex table\n",
    "\n",
    "bandsDataframe.to_csv(result + datasetName + \"bandsAndWavelenghts.csv\",index=None, sep=' ', mode='w')\n",
    "\n",
    "print(bandsDataframe.round(3).to_latex(index=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays selected bands over clasess average\n",
    "titleFig = \"Promedio clases\"\n",
    "#Per class samples\n",
    "_, ClassCount = np.unique(Labels, return_counts=True)\n",
    "print(ClassCount)\n",
    "\n",
    "CornAlone = pd.DataFrame(Data.T)\n",
    "\n",
    "CornMeanPerNitrogen = pd.DataFrame({\"25\":CornAlone.iloc[:,:ClassCount[0]].mean(axis = 1),   \n",
    "                                    \"50\":CornAlone.iloc[:,ClassCount[0]:ClassCount.cumsum()[1]].mean(axis = 1),    \n",
    "                                    \"75\":CornAlone.iloc[:,ClassCount.cumsum()[1]:ClassCount.cumsum()[2]].mean(axis = 1),   \n",
    "                                    \"100\":CornAlone.iloc[:,ClassCount.cumsum()[2]:].mean(axis = 1)}) \n",
    "\n",
    "plt.grid(False)\n",
    "plt.ylabel('Reflectancia')\n",
    "plt.xlabel('Ancho de Banda (nm)')\n",
    "\n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"25\"], label='25N')  \n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"50\"], label='50N') \n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"75\"], label='75N') \n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"100\"], label='100N') \n",
    "plt.legend()\n",
    "plt.title(titleFig)\n",
    "\n",
    "#for a in range(0,20):\n",
    "#    plt.axvline(x=CornData.iloc[bands_selected['bombs'][4][a]-1]['wavelengths'], color='k', linestyle='--')\n",
    "\n",
    "plt.savefig(result + datasetName + titleFig + '.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays selected bands over calsses average\n",
    "\n",
    "alg = \"svd\"\n",
    "n_bands = 20\n",
    "\n",
    "titleFig = f\"{n_bands} bandas {alg}\"\n",
    "\n",
    "#Per class samples\n",
    "_, ClassCount = np.unique(Labels, return_counts=True)\n",
    "print(ClassCount)\n",
    "\n",
    "CornAlone = pd.DataFrame(Data.T)\n",
    "\n",
    "CornMeanPerNitrogen = pd.DataFrame({\"25\":CornAlone.iloc[:,:ClassCount[0]].mean(axis = 1),   \n",
    "                                    \"50\":CornAlone.iloc[:,ClassCount[0]:ClassCount.cumsum()[1]].mean(axis = 1),    \n",
    "                                    \"75\":CornAlone.iloc[:,ClassCount.cumsum()[1]:ClassCount.cumsum()[2]].mean(axis = 1),   \n",
    "                                    \"100\":CornAlone.iloc[:,ClassCount.cumsum()[2]:].mean(axis = 1)}) \n",
    "\n",
    "plt.grid(False)\n",
    "plt.ylabel('Reflectancia')\n",
    "plt.xlabel('Ancho de Banda (nm)')\n",
    "\n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"25\"], label='25N')  \n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"50\"], label='50N') \n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"75\"], label='75N') \n",
    "plt.plot(Wavelength, CornMeanPerNitrogen[\"100\"], label='100N') \n",
    "plt.title(titleFig)\n",
    "\n",
    "for a in range(0,n_bands):\n",
    "    plt.axvline(x=Wavelength[0][bands_selected[alg][int(n_bands/factor)-1][a]], color='dimgray', linestyle='--')\n",
    "\n",
    "plt.savefig(result + datasetName + titleFig + '.eps', format='eps')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix Experiment 1 all clases\n",
    "\n",
    "#this section retrains specific classifier and selected bands to create a confusion matrix\n",
    "\n",
    "#takes selected bands from dataset\n",
    "\n",
    "n_bands = 20\n",
    "alg = \"svd\"\n",
    "\n",
    "DataSelected = Data[:,bands_selected[alg][int((n_bands/factor) -1),0:n_bands]]\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(DataSelected, Labels,\n",
    "                                                    test_size=0.15, random_state=11, stratify = Labels)\n",
    "\n",
    "\n",
    "#training classification algorithm\n",
    "\n",
    "experiment1 = SVM.fit(X_train, y_train.ravel())\n",
    "\n",
    "#Prediction of test data\n",
    "\n",
    "predictEX1 = experiment1.predict(X_test)\n",
    "\n",
    "#Creating confusion matrix\n",
    "\n",
    "names = [\"25N\", \"50N\", \"75N\" , \"100N\"]\n",
    "\n",
    "matrix = metrics.confusion_matrix(y_test, predictEX1)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in matrix.flatten()/np.sum(matrix)]\n",
    "anotattion = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "          zip(group_counts,group_percentages)]\n",
    "anotattion = np.asarray(anotattion).reshape(4,4)\n",
    "\n",
    "plt.figure()\n",
    "immat = sn.heatmap(matrix,cmap=\"Blues\", cbar=False, annot=anotattion, fmt='', xticklabels = names, yticklabels = names)\n",
    "\n",
    "titleFig = \"Matríz de confusión Ex1\"\n",
    "\n",
    "\n",
    "plt.title(titleFig)\n",
    "\n",
    "plt.savefig(result + datasetName + titleFig + '.eps', format='eps')\n",
    "\n",
    "print(metrics.classification_report(y_test, predictEX1, target_names = names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix Experiment 2 Two clases\n",
    "\n",
    "#this section retrains specific classifier and selected bands to create a confusion matrix\n",
    "\n",
    "#cuts data to take only two clases\n",
    "condition = (Labels == 2) | (Labels == 4)\n",
    "Datadf = pd.DataFrame(Data)\n",
    "Datacut = np.array(Datadf.loc[condition])\n",
    "Labelsdf = pd.DataFrame(Labels)\n",
    "Labelscut = np.array(Labelsdf.loc[condition])\n",
    "\n",
    "#takes selected bands from dataset\n",
    "n_bands = 28\n",
    "alg = \"bombs\"\n",
    "\n",
    "DataSelected = Datacut[:,bands_selected[alg][int((n_bands/factor) -1),0:n_bands]]\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(DataSelected, Labelscut,\n",
    "                                                    test_size=0.15, random_state=11, stratify = Labelscut)\n",
    "\n",
    "#training classification algorithm\n",
    "\n",
    "experiment2 = SVM.fit(X_train, y_train.ravel())\n",
    "\n",
    "#Prediction of test data\n",
    "\n",
    "predictEX2 = experiment2.predict(X_test)\n",
    "\n",
    "#Creating confusion matrix\n",
    "\n",
    "names = [\"50N\", \"100N\"]\n",
    "\n",
    "matrix = metrics.confusion_matrix(y_test, predictEX2)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in matrix.flatten()/np.sum(matrix)]\n",
    "anotattion = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "          zip(group_counts,group_percentages)]\n",
    "anotattion = np.asarray(anotattion).reshape(2,2)\n",
    "\n",
    "plt.figure()\n",
    "immat = sn.heatmap(matrix,cmap=\"Blues\", cbar=False, annot=anotattion, fmt='', xticklabels = names, yticklabels = names)\n",
    "\n",
    "titleFig = \"Matríz de confusión Ex2\"\n",
    "\n",
    "plt.title(titleFig)\n",
    "\n",
    "plt.savefig(result + datasetName + titleFig + '.eps', format='eps')\n",
    "\n",
    "print(metrics.classification_report(y_test, predictEX2, target_names = names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caed13605e53eb35d6b9773eea389f3214f7b2918db3fc1779ae048d6a15861c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
